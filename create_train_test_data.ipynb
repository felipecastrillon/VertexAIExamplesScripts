{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "feb8627a-8282-4e8b-a5ad-7185ee0981c3",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution -roto-plus (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -rotobuf (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting pandas_gbq\n",
      "  Downloading pandas_gbq-0.19.2-py2.py3-none-any.whl (25 kB)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from pandas_gbq) (68.0.0)\n",
      "Requirement already satisfied: db-dtypes<2.0.0,>=1.0.4 in /opt/conda/lib/python3.10/site-packages (from pandas_gbq) (1.1.1)\n",
      "Requirement already satisfied: numpy>=1.16.6 in /opt/conda/lib/python3.10/site-packages (from pandas_gbq) (1.23.5)\n",
      "Requirement already satisfied: pandas>=1.1.4 in /opt/conda/lib/python3.10/site-packages (from pandas_gbq) (2.0.3)\n",
      "Requirement already satisfied: pyarrow>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from pandas_gbq) (12.0.1)\n",
      "Collecting pydata-google-auth>=1.5.0 (from pandas_gbq)\n",
      "  Obtaining dependency information for pydata-google-auth>=1.5.0 from https://files.pythonhosted.org/packages/28/6b/3320c9ddbfc572108917e8432a07e8bd1e40054d94b5ad40c755afdc1160/pydata_google_auth-1.8.2-py2.py3-none-any.whl.metadata\n",
      "  Downloading pydata_google_auth-1.8.2-py2.py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: google-api-core<3.0.0dev,>=2.10.2 in ./.local/lib/python3.10/site-packages (from pandas_gbq) (2.11.1)\n",
      "Requirement already satisfied: google-auth>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from pandas_gbq) (2.22.0)\n",
      "Requirement already satisfied: google-auth-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from pandas_gbq) (1.0.0)\n",
      "Requirement already satisfied: google-cloud-bigquery!=2.4.*,<4.0.0dev,>=3.3.5 in /opt/conda/lib/python3.10/site-packages (from pandas_gbq) (3.11.4)\n",
      "Requirement already satisfied: google-cloud-bigquery-storage<3.0.0dev,>=2.16.2 in /opt/conda/lib/python3.10/site-packages (from pandas_gbq) (2.22.0)\n",
      "Requirement already satisfied: packaging>=17.0 in /opt/conda/lib/python3.10/site-packages (from db-dtypes<2.0.0,>=1.0.4->pandas_gbq) (23.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core<3.0.0dev,>=2.10.2->pandas_gbq) (1.60.0)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0.dev0,>=3.19.5 in /opt/conda/lib/python3.10/site-packages (from google-api-core<3.0.0dev,>=2.10.2->pandas_gbq) (4.23.0)\n",
      "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /opt/conda/lib/python3.10/site-packages (from google-api-core<3.0.0dev,>=2.10.2->pandas_gbq) (2.31.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth>=2.13.0->pandas_gbq) (5.3.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth>=2.13.0->pandas_gbq) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth>=2.13.0->pandas_gbq) (4.9)\n",
      "Requirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.10/site-packages (from google-auth>=2.13.0->pandas_gbq) (1.16.0)\n",
      "Requirement already satisfied: urllib3<2.0 in /opt/conda/lib/python3.10/site-packages (from google-auth>=2.13.0->pandas_gbq) (1.26.16)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib>=0.7.0->pandas_gbq) (1.3.1)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.47.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-bigquery!=2.4.*,<4.0.0dev,>=3.3.5->pandas_gbq) (1.56.2)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.15.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-bigquery!=2.4.*,<4.0.0dev,>=3.3.5->pandas_gbq) (1.22.2)\n",
      "Requirement already satisfied: google-cloud-core<3.0.0dev,>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-bigquery!=2.4.*,<4.0.0dev,>=3.3.5->pandas_gbq) (2.3.3)\n",
      "Requirement already satisfied: google-resumable-media<3.0dev,>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-bigquery!=2.4.*,<4.0.0dev,>=3.3.5->pandas_gbq) (2.5.0)\n",
      "Requirement already satisfied: python-dateutil<3.0dev,>=2.7.2 in /opt/conda/lib/python3.10/site-packages (from google-cloud-bigquery!=2.4.*,<4.0.0dev,>=3.3.5->pandas_gbq) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.1.4->pandas_gbq) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.1.4->pandas_gbq) (2023.3)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core<3.0.0dev,>=2.10.2->pandas_gbq) (1.48.2)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /opt/conda/lib/python3.10/site-packages (from google-resumable-media<3.0dev,>=0.6.0->google-cloud-bigquery!=2.4.*,<4.0.0dev,>=3.3.5->pandas_gbq) (1.5.0)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth>=2.13.0->pandas_gbq) (0.5.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core<3.0.0dev,>=2.10.2->pandas_gbq) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core<3.0.0dev,>=2.10.2->pandas_gbq) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core<3.0.0dev,>=2.10.2->pandas_gbq) (2023.7.22)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.7.0->pandas_gbq) (3.2.2)\n",
      "Downloading pydata_google_auth-1.8.2-py2.py3-none-any.whl (15 kB)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -roto-plus (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -rotobuf (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: pydata-google-auth, pandas_gbq\n",
      "Successfully installed pandas_gbq-0.19.2 pydata-google-auth-1.8.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas_gbq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb8ca6c4-d051-4ccb-a5c8-56633003a6ad",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29b46319dc514a7aaf284bdab23f5b13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Query is running:   0%|          |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8504462fcd0e418391367b1de1861f59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%bigquery df\n",
    "SELECT * FROM solutions-2023-mar-107.mercari.13K_synthetic_attributes_embeddings \n",
    "WHERE rand() < 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1818aead-4267-4b38-a96f-cf9b4981816c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"golden_data_set.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e765cb42-1a5d-4f62-b379-75386f957c19",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "ArrowTypeError",
     "evalue": "object of type <class 'str'> cannot be converted to int",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mArrowTypeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# upload manually validated set\u001b[39;00m\n\u001b[1;32m      5\u001b[0m df_eval \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgolden_data_set_validated.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m \u001b[43mgbq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_gbq\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_eval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msolutions-2023-mar-107.mercari.13K_synthetic_attributes_embeddings_test\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas_gbq/gbq.py:1220\u001b[0m, in \u001b[0;36mto_gbq\u001b[0;34m(dataframe, destination_table, project_id, chunksize, reauth, if_exists, auth_local_webserver, table_schema, location, progress_bar, credentials, api_method, verbose, private_key, auth_redirect_uri, client_id, client_secret)\u001b[0m\n\u001b[1;32m   1215\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dataframe\u001b[38;5;241m.\u001b[39mempty:\n\u001b[1;32m   1216\u001b[0m     \u001b[38;5;66;03m# Create the table (if needed), but don't try to run a load job with an\u001b[39;00m\n\u001b[1;32m   1217\u001b[0m     \u001b[38;5;66;03m# empty file. See: https://github.com/pydata/pandas-gbq/issues/237\u001b[39;00m\n\u001b[1;32m   1218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m-> 1220\u001b[0m \u001b[43mconnector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1221\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataframe\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1222\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdestination_table_ref\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1223\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwrite_disposition\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwrite_disposition\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1224\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1225\u001b[0m \u001b[43m    \u001b[49m\u001b[43mschema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtable_schema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1226\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1227\u001b[0m \u001b[43m    \u001b[49m\u001b[43mapi_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mapi_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1228\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbilling_project\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproject_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1229\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas_gbq/gbq.py:602\u001b[0m, in \u001b[0;36mGbqConnector.load_data\u001b[0;34m(self, dataframe, destination_table_ref, write_disposition, chunksize, schema, progress_bar, api_method, billing_project)\u001b[0m\n\u001b[1;32m    599\u001b[0m total_rows \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(dataframe)\n\u001b[1;32m    601\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 602\u001b[0m     chunks \u001b[38;5;241m=\u001b[39m \u001b[43mload\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_chunks\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    603\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    604\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdataframe\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    605\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdestination_table_ref\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    606\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[43m        \u001b[49m\u001b[43mschema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    608\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlocation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    609\u001b[0m \u001b[43m        \u001b[49m\u001b[43mapi_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mapi_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    610\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwrite_disposition\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwrite_disposition\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    611\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbilling_project\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbilling_project\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    612\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    613\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m progress_bar \u001b[38;5;129;01mand\u001b[39;00m tqdm:\n\u001b[1;32m    614\u001b[0m         chunks \u001b[38;5;241m=\u001b[39m tqdm\u001b[38;5;241m.\u001b[39mtqdm(chunks)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas_gbq/load.py:243\u001b[0m, in \u001b[0;36mload_chunks\u001b[0;34m(client, dataframe, destination_table_ref, chunksize, schema, location, api_method, write_disposition, billing_project)\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_chunks\u001b[39m(\n\u001b[1;32m    232\u001b[0m     client,\n\u001b[1;32m    233\u001b[0m     dataframe,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    240\u001b[0m     billing_project: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    241\u001b[0m ):\n\u001b[1;32m    242\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m api_method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mload_parquet\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 243\u001b[0m         \u001b[43mload_parquet\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    244\u001b[0m \u001b[43m            \u001b[49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    245\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdataframe\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    246\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdestination_table_ref\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    247\u001b[0m \u001b[43m            \u001b[49m\u001b[43mwrite_disposition\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    248\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    249\u001b[0m \u001b[43m            \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    250\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbilling_project\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbilling_project\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    251\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    252\u001b[0m         \u001b[38;5;66;03m# TODO: yield progress depending on result() with timeout\u001b[39;00m\n\u001b[1;32m    253\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas_gbq/load.py:131\u001b[0m, in \u001b[0;36mload_parquet\u001b[0;34m(client, dataframe, destination_table_ref, write_disposition, location, schema, billing_project)\u001b[0m\n\u001b[1;32m    128\u001b[0m     dataframe \u001b[38;5;241m=\u001b[39m cast_dataframe_for_parquet(dataframe, schema)\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 131\u001b[0m     \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_table_from_dataframe\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    132\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdataframe\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    133\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdestination_table_ref\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[43m        \u001b[49m\u001b[43mjob_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjob_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproject\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbilling_project\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    137\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mresult()\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m pyarrow\u001b[38;5;241m.\u001b[39mlib\u001b[38;5;241m.\u001b[39mArrowInvalid \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    139\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mConversionError(\n\u001b[1;32m    140\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not convert DataFrame to Parquet.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    141\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/cloud/bigquery/client.py:2702\u001b[0m, in \u001b[0;36mClient.load_table_from_dataframe\u001b[0;34m(self, dataframe, destination, num_retries, job_id, job_id_prefix, location, project, job_config, parquet_compression, timeout)\u001b[0m\n\u001b[1;32m   2699\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m parquet_compression \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msnappy\u001b[39m\u001b[38;5;124m\"\u001b[39m:  \u001b[38;5;66;03m# adjust the default value\u001b[39;00m\n\u001b[1;32m   2700\u001b[0m         parquet_compression \u001b[38;5;241m=\u001b[39m parquet_compression\u001b[38;5;241m.\u001b[39mupper()\n\u001b[0;32m-> 2702\u001b[0m     \u001b[43m_pandas_helpers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataframe_to_parquet\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2703\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdataframe\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2704\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnew_job_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2705\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtmppath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2706\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparquet_compression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparquet_compression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2707\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparquet_use_compliant_nested_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   2708\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2709\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2710\u001b[0m     dataframe\u001b[38;5;241m.\u001b[39mto_parquet(\n\u001b[1;32m   2711\u001b[0m         tmppath,\n\u001b[1;32m   2712\u001b[0m         engine\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpyarrow\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2718\u001b[0m         ),\n\u001b[1;32m   2719\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/cloud/bigquery/_pandas_helpers.py:719\u001b[0m, in \u001b[0;36mdataframe_to_parquet\u001b[0;34m(dataframe, bq_schema, filepath, parquet_compression, parquet_use_compliant_nested_type)\u001b[0m\n\u001b[1;32m    712\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    713\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_compliant_nested_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: parquet_use_compliant_nested_type}\n\u001b[1;32m    714\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _helpers\u001b[38;5;241m.\u001b[39mPYARROW_VERSIONS\u001b[38;5;241m.\u001b[39muse_compliant_nested_type\n\u001b[1;32m    715\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[1;32m    716\u001b[0m )\n\u001b[1;32m    718\u001b[0m bq_schema \u001b[38;5;241m=\u001b[39m schema\u001b[38;5;241m.\u001b[39m_to_schema_fields(bq_schema)\n\u001b[0;32m--> 719\u001b[0m arrow_table \u001b[38;5;241m=\u001b[39m \u001b[43mdataframe_to_arrow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbq_schema\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    720\u001b[0m pyarrow\u001b[38;5;241m.\u001b[39mparquet\u001b[38;5;241m.\u001b[39mwrite_table(\n\u001b[1;32m    721\u001b[0m     arrow_table,\n\u001b[1;32m    722\u001b[0m     filepath,\n\u001b[1;32m    723\u001b[0m     compression\u001b[38;5;241m=\u001b[39mparquet_compression,\n\u001b[1;32m    724\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    725\u001b[0m )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/cloud/bigquery/_pandas_helpers.py:662\u001b[0m, in \u001b[0;36mdataframe_to_arrow\u001b[0;34m(dataframe, bq_schema)\u001b[0m\n\u001b[1;32m    659\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m bq_field \u001b[38;5;129;01min\u001b[39;00m bq_schema:\n\u001b[1;32m    660\u001b[0m     arrow_names\u001b[38;5;241m.\u001b[39mappend(bq_field\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m    661\u001b[0m     arrow_arrays\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m--> 662\u001b[0m         \u001b[43mbq_to_arrow_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mget_column_or_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbq_field\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbq_field\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    663\u001b[0m     )\n\u001b[1;32m    664\u001b[0m     arrow_fields\u001b[38;5;241m.\u001b[39mappend(bq_to_arrow_field(bq_field, arrow_arrays[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mtype))\n\u001b[1;32m    666\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mall\u001b[39m((field \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m field \u001b[38;5;129;01min\u001b[39;00m arrow_fields)):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/cloud/bigquery/_pandas_helpers.py:380\u001b[0m, in \u001b[0;36mbq_to_arrow_array\u001b[0;34m(series, bq_field)\u001b[0m\n\u001b[1;32m    378\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m field_type_upper \u001b[38;5;129;01min\u001b[39;00m schema\u001b[38;5;241m.\u001b[39m_STRUCT_TYPES:\n\u001b[1;32m    379\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pyarrow\u001b[38;5;241m.\u001b[39mStructArray\u001b[38;5;241m.\u001b[39mfrom_pandas(series, \u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39marrow_type)\n\u001b[0;32m--> 380\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpyarrow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mArray\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pandas\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseries\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43marrow_type\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pyarrow/array.pxi:1054\u001b[0m, in \u001b[0;36mpyarrow.lib.Array.from_pandas\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pyarrow/array.pxi:323\u001b[0m, in \u001b[0;36mpyarrow.lib.array\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pyarrow/array.pxi:83\u001b[0m, in \u001b[0;36mpyarrow.lib._ndarray_to_array\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pyarrow/error.pxi:123\u001b[0m, in \u001b[0;36mpyarrow.lib.check_status\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mArrowTypeError\u001b[0m: object of type <class 'str'> cannot be converted to int"
     ]
    }
   ],
   "source": [
    "import pandas_gbq as gbq\n",
    "import pandas as pd\n",
    "\n",
    "# upload manually validated set\n",
    "#df_eval = pd.read_csv('golden_data_set_validated.csv')\n",
    "\n",
    "#gbq.to_gbq(df_eval, 'solutions-2023-mar-107.mercari.13K_synthetic_attributes_embeddings_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2bafd623-3faf-4f18-9647-8497856529f6",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Client' object has no attribute 'write_table'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Write the dataframe to BigQuery\u001b[39;00m\n\u001b[1;32m     13\u001b[0m table_ref \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mdataset(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmy_dataset\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mtable(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmy_table\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 14\u001b[0m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_table\u001b[49m(table_ref, df)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Client' object has no attribute 'write_table'"
     ]
    }
   ],
   "source": [
    "from google.cloud import bigquery\n",
    "\n",
    "# Construct a BigQuery client object.\n",
    "client = bigquery.Client()\n",
    "\n",
    "# TODO(developer): Set table_id to the ID of the table to create.\n",
    "# table_id = \"your-project.your_dataset.your_table_name\"\n",
    "\n",
    "job_config = bigquery.LoadJobConfig(\n",
    "    schema=[\n",
    "        bigquery.SchemaField(\"name\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"post_abbr\", \"STRING\"),\n",
    "    ],\n",
    "    skip_leading_rows=1,\n",
    "    # The source format defaults to CSV, so the line below is optional.\n",
    "    source_format=bigquery.SourceFormat.CSV,\n",
    ")\n",
    "uri = \"gs://cloud-samples-data/bigquery/us-states/us-states.csv\"\n",
    "\n",
    "load_job = client.load_table_from_uri(\n",
    "    uri, table_id, job_config=job_config\n",
    ")  # Make an API request.\n",
    "\n",
    "load_job.result()  # Waits for the job to complete.\n",
    "\n",
    "destination_table = client.get_table(table_id)  # Make an API request.\n",
    "print(\"Loaded {} rows.\".format(destination_table.num_rows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "641adfd4-2092-4e16-8dba-ada55ee55c2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on package pandas_gbq:\n",
      "\n",
      "NAME\n",
      "    pandas_gbq\n",
      "\n",
      "DESCRIPTION\n",
      "    # Copyright (c) 2017 pandas-gbq Authors All rights reserved.\n",
      "    # Use of this source code is governed by a BSD-style\n",
      "    # license that can be found in the LICENSE file.\n",
      "\n",
      "PACKAGE CONTENTS\n",
      "    auth\n",
      "    exceptions\n",
      "    features\n",
      "    gbq\n",
      "    load\n",
      "    schema\n",
      "    timestamp\n",
      "    version\n",
      "\n",
      "SUBMODULES\n",
      "    pandas_gbq_version\n",
      "\n",
      "CLASSES\n",
      "    builtins.object\n",
      "        pandas_gbq.gbq.Context\n",
      "    \n",
      "    class Context(builtins.object)\n",
      "     |  Storage for objects to be used throughout a session.\n",
      "     |  \n",
      "     |  A Context object is initialized when the ``pandas_gbq`` module is\n",
      "     |  imported, and can be found at :attr:`pandas_gbq.context`.\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  credentials\n",
      "     |      Credentials to use for Google APIs.\n",
      "     |      \n",
      "     |      These credentials are automatically cached in memory by calls to\n",
      "     |      :func:`pandas_gbq.read_gbq` and :func:`pandas_gbq.to_gbq`. To\n",
      "     |      manually set the credentials, construct an\n",
      "     |      :class:`google.auth.credentials.Credentials` object and set it as\n",
      "     |      the context credentials as demonstrated in the example below. See\n",
      "     |      `auth docs`_ for more information on obtaining credentials.\n",
      "     |      \n",
      "     |      .. _auth docs: http://google-auth.readthedocs.io\n",
      "     |          /en/latest/user-guide.html#obtaining-credentials\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      google.auth.credentials.Credentials\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      \n",
      "     |      Manually setting the context credentials:\n",
      "     |      \n",
      "     |      >>> import pandas_gbq\n",
      "     |      >>> from google.oauth2 import service_account\n",
      "     |      >>> credentials = service_account.Credentials.from_service_account_file(\n",
      "     |      ...     '/path/to/key.json',\n",
      "     |      ... )\n",
      "     |      >>> pandas_gbq.context.credentials = credentials\n",
      "     |  \n",
      "     |  dialect\n",
      "     |      Default dialect to use in :func:`pandas_gbq.read_gbq`.\n",
      "     |      \n",
      "     |      Allowed values for the BigQuery SQL syntax dialect:\n",
      "     |      \n",
      "     |      ``'legacy'``\n",
      "     |          Use BigQuery's legacy SQL dialect. For more information see\n",
      "     |          `BigQuery Legacy SQL Reference\n",
      "     |          <https://cloud.google.com/bigquery/docs/reference/legacy-sql>`__.\n",
      "     |      ``'standard'``\n",
      "     |          Use BigQuery's standard SQL, which is\n",
      "     |          compliant with the SQL 2011 standard. For more information\n",
      "     |          see `BigQuery Standard SQL Reference\n",
      "     |          <https://cloud.google.com/bigquery/docs/reference/standard-sql/>`__.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      str\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      \n",
      "     |      Setting the default syntax to standard:\n",
      "     |      \n",
      "     |      >>> import pandas_gbq\n",
      "     |      >>> pandas_gbq.context.dialect = 'standard'\n",
      "     |  \n",
      "     |  project\n",
      "     |      Default project to use for calls to Google APIs.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      str\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      \n",
      "     |      Manually setting the context project:\n",
      "     |      \n",
      "     |      >>> import pandas_gbq\n",
      "     |      >>> pandas_gbq.context.project = 'my-project'\n",
      "\n",
      "FUNCTIONS\n",
      "    read_gbq(query_or_table, project_id=None, index_col=None, col_order=None, reauth=False, auth_local_webserver=True, dialect=None, location=None, configuration=None, credentials=None, use_bqstorage_api=False, max_results=None, verbose=None, private_key=None, progress_bar_type='tqdm', dtypes=None, auth_redirect_uri=None, client_id=None, client_secret=None)\n",
      "        Load data from Google BigQuery using google-cloud-python\n",
      "        \n",
      "        The main method a user calls to execute a Query in Google BigQuery\n",
      "        and read results into a pandas DataFrame.\n",
      "        \n",
      "        This method uses the Google Cloud client library to make requests to\n",
      "        Google BigQuery, documented `here\n",
      "        <https://googleapis.dev/python/bigquery/latest/index.html>`__.\n",
      "        \n",
      "        See the :ref:`How to authenticate with Google BigQuery <authentication>`\n",
      "        guide for authentication instructions.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        query_or_table : str\n",
      "            SQL query to return data values. If the string is a table ID, fetch the\n",
      "            rows directly from the table without running a query.\n",
      "        project_id : str, optional\n",
      "            Google Cloud Platform project ID. Optional when available from\n",
      "            the environment.\n",
      "        index_col : str, optional\n",
      "            Name of result column to use for index in results DataFrame.\n",
      "        col_order : list(str), optional\n",
      "            List of BigQuery column names in the desired order for results\n",
      "            DataFrame.\n",
      "        reauth : boolean, default False\n",
      "            Force Google BigQuery to re-authenticate the user. This is useful\n",
      "            if multiple accounts are used.\n",
      "        auth_local_webserver : bool, default True\n",
      "            Use the `local webserver flow\n",
      "            <https://googleapis.dev/python/google-auth-oauthlib/latest/reference/google_auth_oauthlib.flow.html#google_auth_oauthlib.flow.InstalledAppFlow.run_local_server>`_\n",
      "            instead of the `console flow\n",
      "            <https://googleapis.dev/python/google-auth-oauthlib/latest/reference/google_auth_oauthlib.flow.html#google_auth_oauthlib.flow.InstalledAppFlow.run_console>`_\n",
      "            when getting user credentials. Your code must run on the same machine\n",
      "            as your web browser and your web browser can access your application\n",
      "            via ``localhost:808X``.\n",
      "        \n",
      "            .. versionadded:: 0.2.0\n",
      "        dialect : str, default 'standard'\n",
      "            Note: The default value changed to 'standard' in version 0.10.0.\n",
      "        \n",
      "            SQL syntax dialect to use. Value can be one of:\n",
      "        \n",
      "            ``'legacy'``\n",
      "                Use BigQuery's legacy SQL dialect. For more information see\n",
      "                `BigQuery Legacy SQL Reference\n",
      "                <https://cloud.google.com/bigquery/docs/reference/legacy-sql>`__.\n",
      "            ``'standard'``\n",
      "                Use BigQuery's standard SQL, which is\n",
      "                compliant with the SQL 2011 standard. For more information\n",
      "                see `BigQuery Standard SQL Reference\n",
      "                <https://cloud.google.com/bigquery/docs/reference/standard-sql/>`__.\n",
      "        location : str, optional\n",
      "            Location where the query job should run. See the `BigQuery locations\n",
      "            documentation\n",
      "            <https://cloud.google.com/bigquery/docs/dataset-locations>`__ for a\n",
      "            list of available locations. The location must match that of any\n",
      "            datasets used in the query.\n",
      "        \n",
      "            .. versionadded:: 0.5.0\n",
      "        configuration : dict, optional\n",
      "            Query config parameters for job processing.\n",
      "            For example:\n",
      "        \n",
      "                configuration = {'query': {'useQueryCache': False}}\n",
      "        \n",
      "            For more information see `BigQuery REST API Reference\n",
      "            <https://cloud.google.com/bigquery/docs/reference/rest/v2/jobs#configuration.query>`__.\n",
      "        credentials : google.auth.credentials.Credentials, optional\n",
      "            Credentials for accessing Google APIs. Use this parameter to override\n",
      "            default credentials, such as to use Compute Engine\n",
      "            :class:`google.auth.compute_engine.Credentials` or Service Account\n",
      "            :class:`google.oauth2.service_account.Credentials` directly.\n",
      "        \n",
      "            .. versionadded:: 0.8.0\n",
      "        use_bqstorage_api : bool, default False\n",
      "            Use the `BigQuery Storage API\n",
      "            <https://cloud.google.com/bigquery/docs/reference/storage/>`__ to\n",
      "            download query results quickly, but at an increased cost. To use this\n",
      "            API, first `enable it in the Cloud Console\n",
      "            <https://console.cloud.google.com/apis/library/bigquerystorage.googleapis.com>`__.\n",
      "            You must also have the `bigquery.readsessions.create\n",
      "            <https://cloud.google.com/bigquery/docs/access-control#roles>`__\n",
      "            permission on the project you are billing queries to.\n",
      "        \n",
      "            This feature requires the ``google-cloud-bigquery-storage`` and\n",
      "            ``pyarrow`` packages.\n",
      "        \n",
      "            This value is ignored if ``max_results`` is set.\n",
      "        \n",
      "            .. versionadded:: 0.10.0\n",
      "        max_results : int, optional\n",
      "            If set, limit the maximum number of rows to fetch from the query\n",
      "            results.\n",
      "        \n",
      "            .. versionadded:: 0.12.0\n",
      "        progress_bar_type (Optional[str]):\n",
      "            If set, use the `tqdm <https://tqdm.github.io/>`__ library to\n",
      "            display a progress bar while the data downloads. Install the\n",
      "            ``tqdm`` package to use this feature.\n",
      "            Possible values of ``progress_bar_type`` include:\n",
      "        \n",
      "            ``None``\n",
      "                No progress bar.\n",
      "            ``'tqdm'``\n",
      "                Use the :func:`tqdm.tqdm` function to print a progress bar\n",
      "                to :data:`sys.stderr`.\n",
      "            ``'tqdm_notebook'``\n",
      "                Use the :func:`tqdm.tqdm_notebook` function to display a\n",
      "                progress bar as a Jupyter notebook widget.\n",
      "            ``'tqdm_gui'``\n",
      "                Use the :func:`tqdm.tqdm_gui` function to display a\n",
      "                progress bar as a graphical dialog box.\n",
      "        dtypes : dict, optional\n",
      "            A dictionary of column names to pandas ``dtype``. The provided\n",
      "            ``dtype`` is used when constructing the series for the column\n",
      "            specified. Otherwise, a default ``dtype`` is used.\n",
      "        verbose : None, deprecated\n",
      "            Deprecated in Pandas-GBQ 0.4.0. Use the `logging module\n",
      "            to adjust verbosity instead\n",
      "            <https://pandas-gbq.readthedocs.io/en/latest/intro.html#logging>`__.\n",
      "        private_key : str, deprecated\n",
      "            Deprecated in pandas-gbq version 0.8.0. Use the ``credentials``\n",
      "            parameter and\n",
      "            :func:`google.oauth2.service_account.Credentials.from_service_account_info`\n",
      "            or\n",
      "            :func:`google.oauth2.service_account.Credentials.from_service_account_file`\n",
      "            instead.\n",
      "        auth_redirect_uri : str\n",
      "            Path to the authentication page for organization-specific authentication\n",
      "            workflows. Used when ``auth_local_webserver=False``.\n",
      "        client_id : str\n",
      "            The Client ID for the Google Cloud Project the user is attempting to\n",
      "            connect to.\n",
      "        client_secret : str\n",
      "            The Client Secret associated with the Client ID for the Google Cloud Project\n",
      "            the user is attempting to connect to.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        df: DataFrame\n",
      "            DataFrame representing results of query.\n",
      "    \n",
      "    to_gbq(dataframe, destination_table, project_id=None, chunksize=None, reauth=False, if_exists='fail', auth_local_webserver=True, table_schema=None, location=None, progress_bar=True, credentials=None, api_method: str = 'default', verbose=None, private_key=None, auth_redirect_uri=None, client_id=None, client_secret=None)\n",
      "        Write a DataFrame to a Google BigQuery table.\n",
      "        \n",
      "        The main method a user calls to export pandas DataFrame contents to Google BigQuery table.\n",
      "        \n",
      "        This method uses the Google Cloud client library to make requests to Google BigQuery, documented `here\n",
      "        <https://googleapis.dev/python/bigquery/latest/index.html>`__.\n",
      "        \n",
      "        See the :ref:`How to authenticate with Google BigQuery <authentication>`\n",
      "        guide for authentication instructions.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        dataframe : pandas.DataFrame\n",
      "            DataFrame to be written to a Google BigQuery table.\n",
      "        destination_table : str\n",
      "            Name of table to be written, in the form ``dataset.tablename`` or\n",
      "            ``project.dataset.tablename``.\n",
      "        project_id : str, optional\n",
      "            Google Cloud Platform project ID. Optional when available from\n",
      "            the environment.\n",
      "        chunksize : int, optional\n",
      "            Number of rows to be inserted in each chunk from the dataframe.\n",
      "            Set to ``None`` to load the whole dataframe at once.\n",
      "        reauth : bool, default False\n",
      "            Force Google BigQuery to re-authenticate the user. This is useful\n",
      "            if multiple accounts are used.\n",
      "        if_exists : str, default 'fail'\n",
      "            Behavior when the destination table exists. Value can be one of:\n",
      "        \n",
      "            ``'fail'``\n",
      "                If table exists, do nothing.\n",
      "            ``'replace'``\n",
      "                If table exists, drop it, recreate it, and insert data.\n",
      "            ``'append'``\n",
      "                If table exists, insert data. Create if does not exist.\n",
      "        auth_local_webserver : bool, default True\n",
      "            Use the `local webserver flow\n",
      "            <https://googleapis.dev/python/google-auth-oauthlib/latest/reference/google_auth_oauthlib.flow.html#google_auth_oauthlib.flow.InstalledAppFlow.run_local_server>`_\n",
      "            instead of the `console flow\n",
      "            <https://googleapis.dev/python/google-auth-oauthlib/latest/reference/google_auth_oauthlib.flow.html#google_auth_oauthlib.flow.InstalledAppFlow.run_console>`_\n",
      "            when getting user credentials. Your code must run on the same machine\n",
      "            as your web browser and your web browser can access your application\n",
      "            via ``localhost:808X``.\n",
      "        \n",
      "            .. versionadded:: 0.2.0\n",
      "        table_schema : list of dicts, optional\n",
      "            List of BigQuery table fields to which according DataFrame\n",
      "            columns conform to, e.g. ``[{'name': 'col1', 'type':\n",
      "            'STRING'},...]``.  The ``type`` values must be BigQuery type names.\n",
      "        \n",
      "            - If ``table_schema`` is provided, it may contain all or a subset of\n",
      "              DataFrame columns. If a subset is provided, the rest will be\n",
      "              inferred from the DataFrame dtypes.  If ``table_schema`` contains\n",
      "              columns not in the DataFrame, they'll be ignored.\n",
      "            - If ``table_schema`` is **not** provided, it will be\n",
      "              generated according to dtypes of DataFrame columns. See\n",
      "              `Inferring the Table Schema\n",
      "              <https://pandas-gbq.readthedocs.io/en/latest/writing.html#writing-schema>`__.\n",
      "              for a description of the schema inference.\n",
      "        \n",
      "            See `BigQuery API documentation on valid column names\n",
      "            <https://cloud.google.com/bigquery/docs/schemas#column_names`>__.\n",
      "        \n",
      "            .. versionadded:: 0.3.1\n",
      "        location : str, optional\n",
      "            Location where the load job should run. See the `BigQuery locations\n",
      "            documentation\n",
      "            <https://cloud.google.com/bigquery/docs/dataset-locations>`__ for a\n",
      "            list of available locations. The location must match that of the\n",
      "            target dataset.\n",
      "        \n",
      "            .. versionadded:: 0.5.0\n",
      "        progress_bar : bool, default True\n",
      "            Use the library `tqdm` to show the progress bar for the upload,\n",
      "            chunk by chunk.\n",
      "        \n",
      "            .. versionadded:: 0.5.0\n",
      "        credentials : google.auth.credentials.Credentials, optional\n",
      "            Credentials for accessing Google APIs. Use this parameter to override\n",
      "            default credentials, such as to use Compute Engine\n",
      "            :class:`google.auth.compute_engine.Credentials` or Service Account\n",
      "            :class:`google.oauth2.service_account.Credentials` directly.\n",
      "        \n",
      "            .. versionadded:: 0.8.0\n",
      "        api_method : str, optional\n",
      "            API method used to upload DataFrame to BigQuery. One of \"load_parquet\",\n",
      "            \"load_csv\". Default \"load_parquet\" if pandas is version 1.1.0+,\n",
      "            otherwise \"load_csv\".\n",
      "        \n",
      "            .. versionadded:: 0.16.0\n",
      "        verbose : bool, deprecated\n",
      "            Deprecated in Pandas-GBQ 0.4.0. Use the `logging module\n",
      "            to adjust verbosity instead\n",
      "            <https://pandas-gbq.readthedocs.io/en/latest/intro.html#logging>`__.\n",
      "        private_key : str, deprecated\n",
      "            Deprecated in pandas-gbq version 0.8.0. Use the ``credentials``\n",
      "            parameter and\n",
      "            :func:`google.oauth2.service_account.Credentials.from_service_account_info`\n",
      "            or\n",
      "            :func:`google.oauth2.service_account.Credentials.from_service_account_file`\n",
      "            instead.\n",
      "        auth_redirect_uri : str\n",
      "            Path to the authentication page for organization-specific authentication\n",
      "            workflows. Used when ``auth_local_webserver=False``.\n",
      "        client_id : str\n",
      "            The Client ID for the Google Cloud Project the user is attempting to\n",
      "            connect to.\n",
      "        client_secret : str\n",
      "            The Client Secret associated with the Client ID for the Google Cloud Project\n",
      "            the user is attempting to connect to.\n",
      "\n",
      "DATA\n",
      "    __all__ = ['__version__', 'to_gbq', 'read_gbq', 'Context', 'context']\n",
      "    context = <pandas_gbq.gbq.Context object>\n",
      "\n",
      "VERSION\n",
      "    0.19.2\n",
      "\n",
      "FILE\n",
      "    /opt/conda/lib/python3.10/site-packages/pandas_gbq/__init__.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(gbq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f03136-05a2-4586-b991-09b57b9f4632",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-root-py",
   "name": "workbench-notebooks.m110",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/workbench-notebooks:m110"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
