{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d91801a4-1da6-4612-bad0-56072bffc273",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: tensorflow\n",
      "Version: 2.3.4\n",
      "Summary: TensorFlow is an open source machine learning framework for everyone.\n",
      "Home-page: https://www.tensorflow.org/\n",
      "Author: Google Inc.\n",
      "Author-email: packages@tensorflow.org\n",
      "License: Apache 2.0\n",
      "Location: /opt/conda/lib/python3.7/site-packages\n",
      "Requires: h5py, opt-einsum, numpy, protobuf, grpcio, termcolor, six, tensorboard, wheel, astunparse, gast, absl-py, google-pasta, wrapt, keras-preprocessing, tensorflow-estimator\n",
      "Required-by: witwidget, tfx, tfx-bsl, tensorflow-transform, tensorflow-serving-api, tensorflow-model-analysis, tensorflow-io, tensorflow-data-validation, tensorflow-cloud, Keras, fairness-indicators, explainable-ai-sdk\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip show tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ccf578d3-2bf8-45d4-aa59-48f8259503a3",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ignoring dataclasses: markers 'python_version < \"3.7\"' don't match your environment\n",
      "Requirement already satisfied: tapas-table-parsing in ./.local/lib/python3.7/site-packages (0.0.1.dev0)\n",
      "Requirement already satisfied: apache-beam[gcp]==2.28.0 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 1)) (2.28.0)\n",
      "Requirement already satisfied: frozendict==1.2 in ./.local/lib/python3.7/site-packages (from -r requirements.txt (line 3)) (1.2)\n",
      "Requirement already satisfied: pandas~=1.0.0 in ./.local/lib/python3.7/site-packages (from -r requirements.txt (line 4)) (1.0.5)\n",
      "Requirement already satisfied: scikit-learn~=0.22.1 in ./.local/lib/python3.7/site-packages (from -r requirements.txt (line 5)) (0.22.2.post1)\n",
      "Requirement already satisfied: tensorflow~=2.3.4 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 6)) (2.3.4)\n",
      "Requirement already satisfied: tf-models-official~=2.2.0 in ./.local/lib/python3.7/site-packages (from -r requirements.txt (line 7)) (2.2.2)\n",
      "Requirement already satisfied: kaggle<1.5.8 in ./.local/lib/python3.7/site-packages (from -r requirements.txt (line 9)) (1.5.6)\n",
      "Requirement already satisfied: tensorflow-probability==0.11.0 in ./.local/lib/python3.7/site-packages (from -r requirements.txt (line 10)) (0.11.0)\n",
      "Requirement already satisfied: tf_slim~=1.1.0 in ./.local/lib/python3.7/site-packages (from -r requirements.txt (line 11)) (1.1.0)\n",
      "Requirement already satisfied: nltk~=3.5 in ./.local/lib/python3.7/site-packages (from -r requirements.txt (line 12)) (3.6.3)\n",
      "Requirement already satisfied: beautifulsoup4==4.9.3 in ./.local/lib/python3.7/site-packages (from -r requirements.txt (line 13)) (4.9.3)\n",
      "Requirement already satisfied: html5lib==1.1 in ./.local/lib/python3.7/site-packages (from -r requirements.txt (line 14)) (1.1)\n",
      "Requirement already satisfied: gensim~=3.8.3 in ./.local/lib/python3.7/site-packages (from -r requirements.txt (line 15)) (3.8.3)\n",
      "Requirement already satisfied: lxml~=4.6.0 in ./.local/lib/python3.7/site-packages (from -r requirements.txt (line 16)) (4.6.3)\n",
      "Requirement already satisfied: cloudpickle==1.4.1 in ./.local/lib/python3.7/site-packages (from -r requirements.txt (line 17)) (1.4.1)\n",
      "Requirement already satisfied: gspread in ./.local/lib/python3.7/site-packages (4.0.1)\n",
      "Requirement already satisfied: google-auth-oauthlib>=0.4.1 in /opt/conda/lib/python3.7/site-packages (from gspread) (0.4.6)\n",
      "Requirement already satisfied: google-auth>=1.12.0 in /opt/conda/lib/python3.7/site-packages (from gspread) (1.35.0)\n",
      "Requirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.7/site-packages (from google-auth>=1.12.0->gspread) (1.16.0)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth>=1.12.0->gspread) (4.2.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth>=1.12.0->gspread) (4.7.2)\n",
      "Requirement already satisfied: setuptools>=40.3.0 in /opt/conda/lib/python3.7/site-packages (from google-auth>=1.12.0->gspread) (58.0.4)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth>=1.12.0->gspread) (0.2.7)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from google-auth-oauthlib>=0.4.1->gspread) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.12.0->gspread) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (3.1.1)\n",
      "Requirement already satisfied: requests>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (2.25.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (2021.5.30)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (1.26.6)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (4.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (2.10)\n",
      "Requirement already satisfied: flask-cors in ./.local/lib/python3.7/site-packages (3.0.10)\n",
      "Requirement already satisfied: Flask>=0.9 in ./.local/lib/python3.7/site-packages (from flask-cors) (2.0.1)\n",
      "Requirement already satisfied: Six in /opt/conda/lib/python3.7/site-packages (from flask-cors) (1.16.0)\n",
      "Requirement already satisfied: click>=7.1.2 in /opt/conda/lib/python3.7/site-packages (from Flask>=0.9->flask-cors) (8.0.1)\n",
      "Requirement already satisfied: Werkzeug>=2.0 in /opt/conda/lib/python3.7/site-packages (from Flask>=0.9->flask-cors) (2.0.1)\n",
      "Requirement already satisfied: itsdangerous>=2.0 in ./.local/lib/python3.7/site-packages (from Flask>=0.9->flask-cors) (2.0.1)\n",
      "Requirement already satisfied: Jinja2>=3.0 in ./.local/lib/python3.7/site-packages (from Flask>=0.9->flask-cors) (3.0.1)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from click>=7.1.2->Flask>=0.9->flask-cors) (4.8.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.local/lib/python3.7/site-packages (from Jinja2>=3.0->Flask>=0.9->flask-cors) (2.0.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->click>=7.1.2->Flask>=0.9->flask-cors) (3.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->click>=7.1.2->Flask>=0.9->flask-cors) (3.10.0.2)\n",
      "Requirement already satisfied: flask-ngrok in ./.local/lib/python3.7/site-packages (0.0.25)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from flask-ngrok) (2.25.1)\n",
      "Requirement already satisfied: Flask>=0.8 in ./.local/lib/python3.7/site-packages (from flask-ngrok) (2.0.1)\n",
      "Requirement already satisfied: Jinja2>=3.0 in ./.local/lib/python3.7/site-packages (from Flask>=0.8->flask-ngrok) (3.0.1)\n",
      "Requirement already satisfied: Werkzeug>=2.0 in /opt/conda/lib/python3.7/site-packages (from Flask>=0.8->flask-ngrok) (2.0.1)\n",
      "Requirement already satisfied: click>=7.1.2 in /opt/conda/lib/python3.7/site-packages (from Flask>=0.8->flask-ngrok) (8.0.1)\n",
      "Requirement already satisfied: itsdangerous>=2.0 in ./.local/lib/python3.7/site-packages (from Flask>=0.8->flask-ngrok) (2.0.1)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from click>=7.1.2->Flask>=0.8->flask-ngrok) (4.8.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.local/lib/python3.7/site-packages (from Jinja2>=3.0->Flask>=0.8->flask-ngrok) (2.0.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->click>=7.1.2->Flask>=0.8->flask-ngrok) (3.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->click>=7.1.2->Flask>=0.8->flask-ngrok) (3.10.0.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->flask-ngrok) (1.26.6)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->flask-ngrok) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests->flask-ngrok) (4.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->flask-ngrok) (2021.5.30)\n",
      "Requirement already satisfied: GPUtil in /opt/conda/lib/python3.7/site-packages (1.4.0)\n",
      "Requirement already satisfied: sentencepiece in /opt/conda/lib/python3.7/site-packages (0.1.96)\n"
     ]
    }
   ],
   "source": [
    "!pip install tapas-table-parsing --user --no-deps -r requirements.txt\n",
    "!pip install gspread --user\n",
    "!pip install flask-cors --user\n",
    "!pip install flask-ngrok --user\n",
    "!pip install GPUtil\n",
    "!pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f38ae477-08ce-4667-8257-05bd7bac804c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "046f9aa2-cc87-49b6-afd1-92c8c2b3858d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tapas\n",
    "import gspread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "366de876-6a78-438e-9f71-37e8852c2b2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying gs://tapas_models/2020_08_05/tapas_wtq_wikisql_sqa_masklm_large_reset.zip...\n",
      "/ [1 files][  3.4 GiB/  3.4 GiB]   51.1 MiB/s                                   \n",
      "Operation completed over 1 objects/3.4 GiB.                                      \n",
      "Archive:  tapas_model.zip\n",
      "   creating: tapas_wtq_wikisql_sqa_masklm_large_reset/\n",
      "  inflating: tapas_wtq_wikisql_sqa_masklm_large_reset/bert_config.json  \n",
      "  inflating: tapas_wtq_wikisql_sqa_masklm_large_reset/README.txt  \n",
      "  inflating: tapas_wtq_wikisql_sqa_masklm_large_reset/model.ckpt.index  \n",
      "  inflating: tapas_wtq_wikisql_sqa_masklm_large_reset/model.ckpt.data-00000-of-00001  \n",
      "  inflating: tapas_wtq_wikisql_sqa_masklm_large_reset/vocab.txt  \n",
      "  inflating: tapas_wtq_wikisql_sqa_masklm_large_reset/model.ckpt.meta  \n"
     ]
    }
   ],
   "source": [
    "! gsutil cp \"gs://tapas_models/2020_08_05/tapas_wtq_wikisql_sqa_masklm_large_reset.zip\" \"tapas_model.zip\" && unzip tapas_model.zip\n",
    "! mv tapas_wtq_wikisql_sqa_masklm_large_reset tapas_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6fd8d14-a61c-4a4a-846a-8cf0a386f7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "def get_available_gpus():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos if x.device_type == 'GPU']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "67e02f48-000f-45e6-91ba-755586a78bc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['name']]\n"
     ]
    }
   ],
   "source": [
    "gc = gspread.service_account(filename='felipe-sandbox-1308e1b345df.json')\n",
    "sh = gc.open(\"efx_test_billing_sample\")\n",
    "print(sh.sheet1.get('A1'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aeb04725-00bf-43e4-97f5-70511bff8a64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TwnUserList\n",
      "efx_test_user_list\n",
      "Billing\n",
      "efx_test_billing_sample\n"
     ]
    }
   ],
   "source": [
    "import gspread\n",
    "\n",
    "googlesheets = {\n",
    "    'TwnUserList':'efx_test_user_list',\n",
    "    'Billing' : 'efx_test_billing_sample'\n",
    "}\n",
    "\n",
    "for sheetName in googlesheets:\n",
    "  print (sheetName)\n",
    "  print(googlesheets[sheetName])\n",
    "  gsheets=gc.open(googlesheets[sheetName])\n",
    "  exec(sheetName + \"= gsheets.worksheet('Sheet1').get_all_values()\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b1c6442c-d4e4-4f65-adfa-b4f08f56dd9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['name', 'department', 'price'], ['John Doe', 'finance', '$10.00'], ['Joe Smith', 'marketing', '$12.00'], ['Jessica Something', 'finance', '$5.00'], ['Jill Here', 'marketing', '$2.00'], ['Joanna There', 'finance', '$1.00'], ['John Doe', 'finance', '$5.00']]\n"
     ]
    }
   ],
   "source": [
    "print (Billing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2916a98c-9488-4619-87e0-e878107292af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "import os \n",
    "import shutil\n",
    "import csv\n",
    "import pandas as pd\n",
    "import IPython\n",
    "\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "\n",
    "from tapas.utils import tf_example_utils\n",
    "from tapas.protos import interaction_pb2\n",
    "from tapas.utils import number_annotation_utils\n",
    "from tapas.scripts import prediction_utils\n",
    "\n",
    "\n",
    "os.makedirs('results/wtq/tf_examples', exist_ok=True)\n",
    "os.makedirs('results/wtq/model', exist_ok=True)\n",
    "with open('results/wtq/model/checkpoint', 'w') as f:\n",
    "  f.write('model_checkpoint_path: \"model.ckpt-0\"')\n",
    "for suffix in ['.data-00000-of-00001', '.index', '.meta']:\n",
    "  shutil.copyfile(f'tapas_model/model.ckpt{suffix}', f'results/wtq/model/model.ckpt-0{suffix}')\n",
    "\n",
    "max_seq_length = 512\n",
    "# max_seq_length=1024\n",
    "vocab_file = \"tapas_model/vocab.txt\"\n",
    "config = tf_example_utils.ClassifierConversionConfig(\n",
    "    vocab_file=vocab_file,\n",
    "    max_seq_length=max_seq_length,\n",
    "    max_column_id=max_seq_length,\n",
    "    max_row_id=max_seq_length,\n",
    "    strip_column_names=False,\n",
    "    add_aggregation_candidates=False,\n",
    ")\n",
    "converter = tf_example_utils.ToClassifierTensorflowExample(config)\n",
    "\n",
    "def convert_interactions_to_examples(tables_and_queries):\n",
    "  \"\"\"Calls Tapas converter to convert interaction to example.\"\"\"\n",
    "  for idx, (table, queries) in enumerate(tables_and_queries):\n",
    "    interaction = interaction_pb2.Interaction()\n",
    "    for position, query in enumerate(queries):\n",
    "      question = interaction.questions.add()\n",
    "      question.original_text = query\n",
    "      question.id = f\"{idx}-0_{position}\"\n",
    "    for header in table[0]:\n",
    "      interaction.table.columns.add().text = header\n",
    "    for line in table[1:]:\n",
    "      row = interaction.table.rows.add()\n",
    "      for cell in line:\n",
    "        row.cells.add().text = cell\n",
    "    number_annotation_utils.add_numeric_values(interaction)\n",
    "    for i in range(len(interaction.questions)):\n",
    "      try:\n",
    "        yield converter.convert(interaction, i)\n",
    "      except ValueError as e:\n",
    "        print(f\"Can't convert interaction: {interaction.id} error: {e}\")\n",
    "        \n",
    "def write_tf_example(filename, examples):\n",
    "  with tf.io.TFRecordWriter(filename) as writer:\n",
    "    for example in examples:\n",
    "      writer.write(example.SerializeToString())\n",
    "\n",
    "def aggregation_to_string(index):\n",
    "  if index == 0:\n",
    "    return \"NONE\"\n",
    "  if index == 1:\n",
    "    return \"SUM\"\n",
    "  if index == 2:\n",
    "    return \"AVERAGE\"\n",
    "  if index == 3:\n",
    "    return \"COUNT\"\n",
    "  raise ValueError(f\"Unknown index: {index}\")\n",
    "\n",
    "def predict(table_data, queries):\n",
    "\n",
    "  # Make string a list for function \n",
    "  queries=queries.split(\",\")\n",
    "\n",
    "  #Function to run questions start\n",
    "  # table = [list(map(lambda s: s.strip(), row.split(\"|\"))) \n",
    "  #         for row in table_data.split(\"\\n\") if row.strip()]\n",
    "  table=table_data\n",
    "  # print(table)\n",
    "  examples = convert_interactions_to_examples([(table, queries)])\n",
    "  write_tf_example(\"results/wtq/tf_examples/test.tfrecord\", examples)\n",
    "  write_tf_example(\"results/wtq/tf_examples/random-split-1-dev.tfrecord\", [])\n",
    "\n",
    "  ! python -m tapas.run_task_main \\\n",
    "    --task=\"WTQ\" \\\n",
    "    --output_dir=\"results\" \\\n",
    "    --noloop_predict \\\n",
    "    --test_batch_size={len(queries)} \\\n",
    "    --tapas_verbosity=\"ERROR\" \\\n",
    "    --compression_type= \\\n",
    "    --reset_position_index_per_cell \\\n",
    "    --init_checkpoint=\"tapas_model/model.ckpt\" \\\n",
    "    --bert_config_file=\"tapas_model/bert_config.json\" \\\n",
    "    --mode=\"predict\" 2> error\n",
    "\n",
    "  results_path = \"results/wtq/model/test.tsv\"\n",
    "  all_coordinates = []\n",
    "  df = pd.DataFrame(table[1:], columns=table[0])\n",
    "  display(IPython.display.HTML(df.to_html(index=False)))\n",
    "  # htmltable=IPython.display.HTML(df.to_html(index=False))\n",
    "  print()\n",
    "  results=[]\n",
    "  with open(results_path) as csvfile:\n",
    "    reader = csv.DictReader(csvfile, delimiter='\\t')\n",
    "    for row in reader:\n",
    "      coordinates = sorted(prediction_utils.parse_coordinates(row[\"answer_coordinates\"]))\n",
    "      all_coordinates.append(coordinates)\n",
    "      answers = '~+= '.join([table[row + 1][col] for row, col in coordinates])\n",
    "      position = int(row['position'])\n",
    "      aggregation = aggregation_to_string(int(row[\"pred_aggr\"]))\n",
    "      # print(\">\", queries[position])\n",
    "      print(\"Question: \", queries[position])\n",
    "      answer_text = str(answers)\n",
    "      if aggregation == 'SUM':\n",
    "        split=answer_text.split(\"~+=\")\n",
    "        # print(split)\n",
    "        arithmetic=sum(list(map(int,split)))\n",
    "        # answer_text= f\"{aggregation} = {arithmetic}\"\n",
    "        answer_text= f\"Answer: {arithmetic}\"\n",
    "        # print(answer_text)\n",
    "      elif aggregation == 'COUNT':\n",
    "        split=answer_text.split(\"~+=\")\n",
    "        # print(split)\n",
    "        arithmetic=len(split)\n",
    "        # answer_text= f\"{aggregation} = {arithmetic}\"\n",
    "        answer_text= f\"Answer: {arithmetic}\"\n",
    "      elif aggregation == 'AVERAGE':\n",
    "        split=answer_text.split(\"~+=\")\n",
    "        # print(split)\n",
    "        arithmetic=sum(list(map(int,split)))/len(split)\n",
    "        # answer_text= f\"{aggregation} = {arithmetic}\"\n",
    "        answer_text= f\"Answer: {arithmetic}\"\n",
    "        # print(answer_text)\n",
    "      else:\n",
    "        answer_text= f\"Answer: {answer_text}\"\n",
    "        answer_text=answer_text.replace(\"~+=\",\",\")\n",
    "       \n",
    "      print(answer_text)\n",
    "      print('Coordinates Below:')\n",
    "      print(all_coordinates)\n",
    "      print(\"\\n-----------------------------------\\n\")\n",
    "      results.append(answer_text.replace(\"Answer: \",\"\"))\n",
    "  return queries,results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4611655-a8c7-464c-9e30-5e2b4f46d439",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__' (lazy loading)\n",
      " * Environment: production\n",
      "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
      "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ImmutableMultiDict([('q', '\"can you get me a list of  managers?\"'), ('ds', 'efx_test_user_list')])\n",
      "is_built_with_cuda: True\n",
      "is_gpu_available: True\n",
      "GPUs: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "Training or predicting ...\n",
      "Evaluation finished after training step 0.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>user</th>\n",
       "      <th>department</th>\n",
       "      <th>role</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>John Doe</td>\n",
       "      <td>finance</td>\n",
       "      <td>manager</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Joe Smith</td>\n",
       "      <td>marketing</td>\n",
       "      <td>director</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Jessica Something</td>\n",
       "      <td>finance</td>\n",
       "      <td>director</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Jill Here</td>\n",
       "      <td>marketing</td>\n",
       "      <td>manager</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Joanna There</td>\n",
       "      <td>finance</td>\n",
       "      <td>director</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [07/Oct/2021 19:22:11] \"GET /question?q=\"can%20you%20get%20me%20a%20list%20of%20%20managers?\"&ds=efx_test_user_list HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Question:  \"can you get me a list of  managers?\"\n",
      "Answer: 2\n",
      "Coordinates Below:\n",
      "[[(0, 0), (3, 0)]]\n",
      "\n",
      "-----------------------------------\n",
      "\n",
      "ImmutableMultiDict([('q', '\"give me all the names?\"'), ('ds', 'efx_test_billing_sample')])\n",
      "is_built_with_cuda: True\n",
      "is_gpu_available: True\n",
      "GPUs: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "Training or predicting ...\n",
      "Evaluation finished after training step 0.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>name</th>\n",
       "      <th>department</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>John Doe</td>\n",
       "      <td>finance</td>\n",
       "      <td>$10.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Joe Smith</td>\n",
       "      <td>marketing</td>\n",
       "      <td>$12.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Jessica Something</td>\n",
       "      <td>finance</td>\n",
       "      <td>$5.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Jill Here</td>\n",
       "      <td>marketing</td>\n",
       "      <td>$2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Joanna There</td>\n",
       "      <td>finance</td>\n",
       "      <td>$1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>John Doe</td>\n",
       "      <td>finance</td>\n",
       "      <td>$5.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [07/Oct/2021 19:25:26] \"GET /question?q=\"give%20me%20all%20the%20names?\"&ds=efx_test_billing_sample HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Question:  \"give me all the names?\"\n",
      "Answer: John Doe, Joe Smith, Jessica Something, Jill Here, Joanna There, John Doe\n",
      "Coordinates Below:\n",
      "[[(0, 0), (1, 0), (2, 0), (3, 0), (4, 0), (5, 0)]]\n",
      "\n",
      "-----------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask,request,jsonify\n",
    "from flask import request\n",
    "\n",
    "app = Flask(__name__)\n",
    "app.config['JSON_SORT_KEYS'] = False\n",
    "\n",
    "@app.route(\"/\", methods=['GET'])\n",
    "def home():\n",
    "  return jsonify({'msg': 'Server running'})\n",
    "\n",
    "@app.route(\"/question\", methods=['GET'])\n",
    "def question():\n",
    "  #get args from get request\n",
    "  args = request.args\n",
    "  print(args)\n",
    "  # getting argumnets\n",
    "  questions = args.get('q')\n",
    "  datasheet = args.get('ds')\n",
    " \n",
    "  #if datasheet=='x':\n",
    "  #  dataset = TwnSubmission\n",
    "  if datasheet=='efx_test_user_list':\n",
    "    dataset=TwnUserList\n",
    "  #elif sheet=='x':\n",
    "  #  dataset=DashboardQuestion\n",
    "  #elif sheet=='x':\n",
    "  #  dataset=Batch\n",
    "  elif datasheet=='efx_test_billing_sample':\n",
    "    dataset=Billing\n",
    "  #elif sheet=='x':\n",
    "  #  dataset=FulfillmentRate\n",
    "\n",
    "  #submit to NQL function \n",
    "  queries,results=predict(dataset,questions)\n",
    "\n",
    "  listReturn=[]\n",
    "  for x in range(0,len(queries)):\n",
    "    line={'index': x , 'question': queries[x] , 'answer': results[x]}\n",
    "    listReturn.append(line)\n",
    "\n",
    "  listReturn=jsonify(listReturn)\n",
    "  return listReturn\n",
    "app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205faf5e-3a44-4e15-b8c4-28d627b05966",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-root-py",
   "name": "workbench-notebooks.m110",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/workbench-notebooks:m110"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
